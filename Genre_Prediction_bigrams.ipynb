{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f936d5b-fdc0-454c-a640-94e22ff9c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import LSTM,Dense,Dropout, Reshape, Conv1D, GlobalMaxPooling1D, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,SimpleRNN\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "\n",
    "import ast\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c73832-cd71-4e72-98ab-7d8065513bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "import io\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket('nlp_final_data')\n",
    "\n",
    "blob = bucket.blob('songs_combined_ngrams.csv')\n",
    "content = blob.download_as_string()\n",
    "\n",
    "df = pd.read_csv(io.BytesIO(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a42ce5-04fc-4d40-92ac-e0c82a043538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2f6d0e-6e35-43ca-9127-fb1d30e471ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['up_to_bigrams'] = df['up_to_bigrams'].apply(lambda x: x.strip('[]').replace('\\'', '').split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f0fcc-6fba-41fc-987c-4ff9ffc00e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['up_to_bigrams']\n",
    "y = df['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a10692a-4b32-468a-b627-b13a9ced0167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9b8ebb-1d70-4d17-be3b-9b9f9eb2433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the balanced data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2,stratify=y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d3daa2-02bc-4ac9-b8ef-b6fe434e431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = Tokenizer(char_level=False)\n",
    "tokenize.fit_on_texts(X)\n",
    "\n",
    "# we will need this later\n",
    "num_words = len(tokenize.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959d50bb-62db-4876-8830-4ba060f017f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_words is 496351 with just tokens, and not cleaned\n",
    "#num_words is 46207 when data is lemmatized and cleaned\n",
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996ea3b-28d8-4893-87f2-1b6af855857f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d649a20b-1bc0-4746-9dd8-d3e77f6abea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenize.texts_to_sequences(X_train)\n",
    "x_test = tokenize.texts_to_sequences(X_test)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f206a9-a9f4-42e9-be35-838d39165f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_log_length = 1024\n",
    "x_train = pad_sequences(x_train, maxlen=max_log_length)\n",
    "x_test = pad_sequences(x_test, maxlen=max_log_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad194e-5d1b-44ac-b7a2-58121735ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Embedding(input_dim=num_words,output_dim=64,input_length=max_log_length))\n",
    "\n",
    "num_filters = 128\n",
    "kernel_sizes = [3,4]\n",
    "for kernel_size in kernel_sizes:\n",
    "    model3.add(Conv1D(num_filters, kernel_size, activation='relu'))\n",
    "#model3.add(Conv1D(128, 3, activation='relu'))\n",
    "\n",
    "model3.add(MaxPooling1D(pool_size=2))\n",
    "model3.add(LSTM(units=64,recurrent_dropout=0.5))\n",
    "model3.add(Dropout(0.5))\n",
    "\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "    \n",
    "model3.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ae2b9-28f3-4605-89ee-b142aebeff00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d51651-ae6c-4464-946c-b5cd0f504e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model3.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=3,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595fab9-2865-4255-8c34-f47f32980dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('model_bigrams.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd90ee-a5b8-43bd-99c4-b073c4dd47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_name = 'model_bigrams.h5'\n",
    "client = storage.Client()\n",
    "\n",
    "blob = bucket.blob(blob_name)\n",
    "blob.upload_from_filename(blob_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2ccef-7d27-4f40-a83d-bb39b0692049",
   "metadata": {},
   "source": [
    "Using convolutional layers in a neural network for text data can be beneficial for several reasons:\n",
    "\n",
    "Local Pattern Extraction: Convolutional layers can effectively capture local patterns and features in the text data. By applying filters of different sizes, the convolutional operation can detect patterns at various levels of granularity. This allows the model to learn relevant features such as n-grams, word combinations, or other local patterns that are indicative of the text's meaning or sentiment.\n",
    "\n",
    "Translation Invariance: Convolutional layers exhibit translation invariance, which means they can recognize patterns regardless of their exact position in the input. In the context of text data, this property is useful because the position of a particular word or phrase in a sentence may not always be critical for understanding its meaning. By capturing patterns irrespective of their location, convolutional layers can provide robust representations that are not overly sensitive to word order.\n",
    "\n",
    "Reduced Parameter Count: Convolutional layers can help reduce the number of parameters in the model compared to fully connected layers. This reduction is achieved by weight sharing through the use of filters. By sharing weights, the model can capture the same pattern or feature across different positions in the input, resulting in fewer trainable parameters. This parameter efficiency can make the model easier to train and less prone to overfitting, especially when dealing with limited amounts of text data.\n",
    "\n",
    "Hierarchical Feature Learning: Deep architectures with multiple convolutional layers can learn hierarchical representations of the input text. Lower-level convolutional layers can capture basic local features, while higher-level convolutional layers can learn more complex combinations of these features. This hierarchical learning enables the model to capture both low-level and high-level semantic information from the text.\n",
    "\n",
    "It's worth noting that while convolutional neural networks (CNNs) have primarily been associated with image processing tasks, they have been successfully adapted for natural language processing (NLP) tasks, including text classification. The convolutional operations in text CNNs are typically performed along the time dimension (i.e., word or character sequences) rather than across spatial dimensions (as in image CNNs).\n",
    "\n",
    "That being said, the effectiveness of using convolutional layers in text classification tasks may vary depending on the specific dataset and problem. It's recommended to experiment with different architectures and compare the performance with other approaches, such as recurrent neural networks (RNNs) or transformers, to determine the best choice for your particular task.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Regenerate response"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
