{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f936d5b-fdc0-454c-a640-94e22ff9c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import LSTM,Dense,Dropout, Reshape, Conv1D, GlobalMaxPooling1D, MaxPooling1D, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,SimpleRNN\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72c73832-cd71-4e72-98ab-7d8065513bf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_4663/4125098960.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#blob = bucket.blob('data_no_stop.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'songs_nGrams.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_as_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf_1grams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/storage/blob.py\u001b[0m in \u001b[0;36mdownload_as_string\u001b[0;34m(self, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, retry)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mif_metageneration_not_match\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mif_metageneration_not_match\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m         )\n\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/storage/blob.py\u001b[0m in \u001b[0;36mdownload_as_bytes\u001b[0;34m(self, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001b[0m\n\u001b[1;32m   1399\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m             \u001b[0mchecksum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchecksum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m         )\n\u001b[1;32m   1403\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstring_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/storage/client.py\u001b[0m in \u001b[0;36mdownload_blob_to_file\u001b[0;34m(self, blob_or_uri, file_obj, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mchecksum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchecksum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m                 \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m             )\n\u001b[1;32m   1103\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mresumable_media\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidResponse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/storage/blob.py\u001b[0m in \u001b[0;36m_do_download\u001b[0;34m(self, transport, file_obj, download_url, headers, start, end, raw_download, timeout, checksum, retry)\u001b[0m\n\u001b[1;32m    982\u001b[0m             )\n\u001b[1;32m    983\u001b[0m             \u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_headers_from_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/resumable_media/requests/download.py\u001b[0m in \u001b[0;36mconsume\u001b[0;34m(self, transport, timeout)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         return _request_helpers.wait_and_retry(\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mretriable_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_status_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         )\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/resumable_media/requests/_request_helpers.py\u001b[0m in \u001b[0;36mwait_and_retry\u001b[0;34m(func, get_status_code, retry_strategy)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_CONNECTION_ERROR_CLASSES\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m  \u001b[0;31m# Fall through to retry, if there are retries left.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/resumable_media/requests/download.py\u001b[0m in \u001b[0;36mretriable_request\u001b[0;34m()\u001b[0m\n\u001b[1;32m    231\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bytes_downloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_to_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/resumable_media/requests/download.py\u001b[0m in \u001b[0;36m_write_to_stream\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_request_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SINGLE_GET_CHUNK_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_unicode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             )\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbody_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bytes_downloaded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                 \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "import io\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket('nlp_final_data')\n",
    "\n",
    "#blob = bucket.blob('data_no_stop.csv')\n",
    "blob = bucket.blob('songs_nGrams.csv')\n",
    "content = blob.download_as_string()\n",
    "\n",
    "df_1grams = pd.read_csv(io.BytesIO(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "776d5766-fe9e-451d-8583-bd9246e5a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_tokenized'] = df['data_tokenized'].apply(lambda x: x.strip('[]').replace('\\'', '').split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0766998d-a271-40a0-bdb2-d314be6876af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_tokens'] = df['1-grams'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "69dee55f-9155-446c-8056-e907f8698a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[df.num_tokens<1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31f3a3b9-cfb6-4f97-902f-537a4878cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new[df_new.num_tokens>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0884ecff-3e9d-4e91-bb64-ec8f1f165a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>tokens_no_stop</th>\n",
       "      <th>1-grams</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42727</th>\n",
       "      <td>42727</td>\n",
       "      <td>Math Hoffa vs. John John Da Don</td>\n",
       "      <td>rap</td>\n",
       "      <td>URLtv</td>\n",
       "      <td>['make', 'worst', 'life', 'decisions', 'ive', ...</td>\n",
       "      <td>[make, worst, life, long, virus, battle, rap, ...</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8706</th>\n",
       "      <td>8706</td>\n",
       "      <td>Ridin Dirty VS. The Chronic</td>\n",
       "      <td>rap</td>\n",
       "      <td>Rap Genius Users</td>\n",
       "      <td>['truthisgravey', 'ridin', 'dirty', 'ugk', 'op...</td>\n",
       "      <td>[dirty, opening, statement, underground, bette...</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79287</th>\n",
       "      <td>79287</td>\n",
       "      <td>Invitation</td>\n",
       "      <td>rap</td>\n",
       "      <td>Aha Gazelle</td>\n",
       "      <td>['youre', 'real', 'youre', 'playing', 'dont', ...</td>\n",
       "      <td>[real, dont, believe, word, saying, think, foo...</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20382</th>\n",
       "      <td>20382</td>\n",
       "      <td>Block Cypher</td>\n",
       "      <td>rap</td>\n",
       "      <td>EC1 (Bourne Estate)</td>\n",
       "      <td>['put', 'holes', 'tops', 'gang', 'got', 'opps'...</td>\n",
       "      <td>[put, top, gang, got, co, step, waist, get, fi...</td>\n",
       "      <td>958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71344</th>\n",
       "      <td>71344</td>\n",
       "      <td>100 Bulletz vs JC</td>\n",
       "      <td>rap</td>\n",
       "      <td>King of the Dot</td>\n",
       "      <td>['bulletz', 'vs', 'julian', 'carter', 'lets', ...</td>\n",
       "      <td>[carter, set, every, battle, gon, knock, boy, ...</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190621</th>\n",
       "      <td>190621</td>\n",
       "      <td>Ten Tables</td>\n",
       "      <td>rock</td>\n",
       "      <td>Goon</td>\n",
       "      <td>['way', 'home', 'mottled', 'vine', 'pain', 'pa...</td>\n",
       "      <td>[way, home, mottled, vine, pain, pin, nine, il...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359735</th>\n",
       "      <td>359735</td>\n",
       "      <td>Man The Harpoons</td>\n",
       "      <td>country</td>\n",
       "      <td>The Lost Episode</td>\n",
       "      <td>['instrumental', 'track', 'whilst', 'supposed'...</td>\n",
       "      <td>[instrumental, track, whilst, supposed, decide...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179290</th>\n",
       "      <td>179290</td>\n",
       "      <td>I Told You</td>\n",
       "      <td>rock</td>\n",
       "      <td>Frst</td>\n",
       "      <td>['mist', 'closing', 'mist', 'closing', 'like',...</td>\n",
       "      <td>[mist, mist, like, ghost, cheek, like, like, o...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228388</th>\n",
       "      <td>228388</td>\n",
       "      <td>Nerve Gas</td>\n",
       "      <td>rock</td>\n",
       "      <td>Guided by Voices</td>\n",
       "      <td>['must', 'master', 'nerve', 'shall', 'must', '...</td>\n",
       "      <td>[must, master, nerve, shall, must, slit, dead,...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174454</th>\n",
       "      <td>174454</td>\n",
       "      <td>Keeps Us Together</td>\n",
       "      <td>rock</td>\n",
       "      <td>STRFKR</td>\n",
       "      <td>['best', 'keeps', 'us', 'together', 'best', 'k...</td>\n",
       "      <td>[best, u, together, best, u, together, best, u...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>430253 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                            title      tag  \\\n",
       "42727        42727  Math Hoffa vs. John John Da Don      rap   \n",
       "8706          8706      Ridin Dirty VS. The Chronic      rap   \n",
       "79287        79287                       Invitation      rap   \n",
       "20382        20382                     Block Cypher      rap   \n",
       "71344        71344                100 Bulletz vs JC      rap   \n",
       "...            ...                              ...      ...   \n",
       "190621      190621                       Ten Tables     rock   \n",
       "359735      359735                 Man The Harpoons  country   \n",
       "179290      179290                       I Told You     rock   \n",
       "228388      228388                        Nerve Gas     rock   \n",
       "174454      174454                Keeps Us Together     rock   \n",
       "\n",
       "                     artist  \\\n",
       "42727                 URLtv   \n",
       "8706       Rap Genius Users   \n",
       "79287           Aha Gazelle   \n",
       "20382   EC1 (Bourne Estate)   \n",
       "71344       King of the Dot   \n",
       "...                     ...   \n",
       "190621                 Goon   \n",
       "359735     The Lost Episode   \n",
       "179290                 Frst   \n",
       "228388     Guided by Voices   \n",
       "174454               STRFKR   \n",
       "\n",
       "                                           tokens_no_stop  \\\n",
       "42727   ['make', 'worst', 'life', 'decisions', 'ive', ...   \n",
       "8706    ['truthisgravey', 'ridin', 'dirty', 'ugk', 'op...   \n",
       "79287   ['youre', 'real', 'youre', 'playing', 'dont', ...   \n",
       "20382   ['put', 'holes', 'tops', 'gang', 'got', 'opps'...   \n",
       "71344   ['bulletz', 'vs', 'julian', 'carter', 'lets', ...   \n",
       "...                                                   ...   \n",
       "190621  ['way', 'home', 'mottled', 'vine', 'pain', 'pa...   \n",
       "359735  ['instrumental', 'track', 'whilst', 'supposed'...   \n",
       "179290  ['mist', 'closing', 'mist', 'closing', 'like',...   \n",
       "228388  ['must', 'master', 'nerve', 'shall', 'must', '...   \n",
       "174454  ['best', 'keeps', 'us', 'together', 'best', 'k...   \n",
       "\n",
       "                                                  1-grams  num_tokens  \n",
       "42727   [make, worst, life, long, virus, battle, rap, ...         978  \n",
       "8706    [dirty, opening, statement, underground, bette...         964  \n",
       "79287   [real, dont, believe, word, saying, think, foo...         960  \n",
       "20382   [put, top, gang, got, co, step, waist, get, fi...         958  \n",
       "71344   [carter, set, every, battle, gon, knock, boy, ...         951  \n",
       "...                                                   ...         ...  \n",
       "190621  [way, home, mottled, vine, pain, pin, nine, il...          11  \n",
       "359735  [instrumental, track, whilst, supposed, decide...          11  \n",
       "179290  [mist, mist, like, ghost, cheek, like, like, o...          11  \n",
       "228388  [must, master, nerve, shall, must, slit, dead,...          11  \n",
       "174454  [best, u, together, best, u, together, best, u...          11  \n",
       "\n",
       "[430253 rows x 7 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.sort_values(by=['num_tokens'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8cb4d67b-7e1e-4ee8-94ce-662a73625d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['data_tokenized']\n",
    "y = df['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2b9b8ebb-1d70-4d17-be3b-9b9f9eb2433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the balanced data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2,stratify=y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "69d3daa2-02bc-4ac9-b8ef-b6fe434e431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = Tokenizer(char_level=False)\n",
    "tokenize.fit_on_texts(X) # only fit on train\n",
    "\n",
    "# we will need this later\n",
    "num_words = len(tokenize.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "959d50bb-62db-4876-8830-4ba060f017f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45920"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d649a20b-1bc0-4746-9dd8-d3e77f6abea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenize.texts_to_sequences(X_train)\n",
    "x_test = tokenize.texts_to_sequences(X_test)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6d8c2929-0e2f-42b4-9edc-cd9ad98054d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for song in x_train:\n",
    "    if len(song)>max_len:\n",
    "        max_len = len(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4d325c76-4303-4ac2-a619-9be07b3111e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "978"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4fdf0bcb-483c-43c7-ac2f-e08bb1fc30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_log_length = max_len\n",
    "x_train = pad_sequences(x_train, maxlen=max_log_length)\n",
    "x_test = pad_sequences(x_test, maxlen=max_log_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "97ad194e-5d1b-44ac-b7a2-58121735ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Embedding(input_dim=num_words,output_dim=64,input_length=max_log_length))\n",
    "\n",
    "num_filters = 128\n",
    "kernel_sizes = [2,3, 4]\n",
    "for kernel_size in kernel_sizes:\n",
    "    model3.add(Conv1D(num_filters, kernel_size, activation='relu'))\n",
    "#model3.add(Conv1D(128, 3, activation='relu'))\n",
    "\n",
    "model3.add(MaxPooling1D(pool_size=2))\n",
    "model3.add(LSTM(units=64,recurrent_dropout=0.5))\n",
    "model3.add(Dropout(0.5))\n",
    "\n",
    "# Add Dense layers\n",
    "hidden_units = [128, 64]\n",
    "for units in hidden_units:\n",
    "    model3.add(Dense(units, activation='relu'))\n",
    "    model3.add(Dropout(0.5))\n",
    "    \n",
    "model3.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1d51651-ae6c-4464-946c-b5cd0f504e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2421/2421 [==============================] - 1807s 745ms/step - loss: 1.2583 - accuracy: 0.4671 - val_loss: 1.1062 - val_accuracy: 0.5559\n",
      "Epoch 2/3\n",
      " 817/2421 [=========>....................] - ETA: 19:17 - loss: 1.1129 - accuracy: 0.5588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2421/2421 [==============================] - 1797s 742ms/step - loss: 1.0382 - accuracy: 0.5892 - val_loss: 1.0247 - val_accuracy: 0.5865\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=3,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3595fab9-2865-4255-8c34-f47f32980dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('model_cleaned_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fcd90ee-a5b8-43bd-99c4-b073c4dd47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_name = 'model_final_05_20.h5'\n",
    "client = storage.Client()\n",
    "\n",
    "blob = bucket.blob(blob_name)\n",
    "blob.upload_from_filename(blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea0212b0-94e3-466e-9e0e-f9b7b1cbb9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Embedding(input_dim=num_words,output_dim=128,input_length=max_log_length))\n",
    "\n",
    "num_filters = 128\n",
    "kernel_sizes = [2,3]\n",
    "for kernel_size in kernel_sizes:\n",
    "    model3.add(Conv1D(num_filters, kernel_size, activation='relu'))\n",
    "#model3.add(Conv1D(128, 3, activation='relu'))\n",
    "\n",
    "model3.add(MaxPooling1D(pool_size=5))\n",
    "model3.add(LSTM(units=64,recurrent_dropout=0.5))\n",
    "model3.add(Dropout(0.5))\n",
    "\n",
    "# Add Dense layers\n",
    "hidden_units = [128, 64]\n",
    "for units in hidden_units:\n",
    "    model3.add(Dense(units, activation='relu'))\n",
    "    model3.add(Dropout(0.5))\n",
    "    \n",
    "model3.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f32cc8c9-af8d-463d-a101-5246d187765b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2438/2438 [==============================] - 986s 403ms/step - loss: 1.1825 - accuracy: 0.5121 - val_loss: 1.0520 - val_accuracy: 0.5676\n",
      "Epoch 2/3\n",
      "2438/2438 [==============================] - 983s 403ms/step - loss: 1.0486 - accuracy: 0.5841 - val_loss: 1.0328 - val_accuracy: 0.5752\n",
      "Epoch 3/3\n",
      "2438/2438 [==============================] - 984s 404ms/step - loss: 0.9983 - accuracy: 0.6038 - val_loss: 1.0325 - val_accuracy: 0.5831\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=3,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aba0df0a-bbd0-458c-a161-5c95afb0c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('model_best_05_20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "feb6b4f6-5181-48b5-a553-8a79689cf997",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_name = 'model_best_05_20.h5'\n",
    "client = storage.Client()\n",
    "\n",
    "blob = bucket.blob(blob_name)\n",
    "blob.upload_from_filename(blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "536bc7b5-18fe-4cd8-98f8-549e3c4e84ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Embedding(input_dim=num_words,output_dim=256,input_length=max_log_length))\n",
    "\n",
    "num_filters = 128\n",
    "kernel_sizes = [3,4,5]\n",
    "for kernel_size in kernel_sizes:\n",
    "    model3.add(Conv1D(num_filters, kernel_size, activation='relu'))\n",
    "#model3.add(Conv1D(128, 3, activation='relu'))\n",
    "\n",
    "model3.add(MaxPooling1D(pool_size=5))\n",
    "model3.add(LSTM(units=128,recurrent_dropout=0.5))\n",
    "model3.add(Dropout(0.5))\n",
    "\n",
    "# Add Dense layers\n",
    "hidden_units = [128, 64]\n",
    "for units in hidden_units:\n",
    "    model3.add(Dense(units, activation='relu'))\n",
    "    model3.add(Dropout(0.5))\n",
    "    \n",
    "model3.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83163aa7-dfd0-46aa-9d7d-e063e9e7b9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2438/2438 [==============================] - 1975s 806ms/step - loss: 1.1744 - accuracy: 0.5203 - val_loss: 1.0538 - val_accuracy: 0.5696\n",
      "Epoch 2/3\n",
      "2438/2438 [==============================] - 1961s 804ms/step - loss: 1.0488 - accuracy: 0.5834 - val_loss: 1.0276 - val_accuracy: 0.5815\n",
      "Epoch 3/3\n",
      "2438/2438 [==============================] - 1967s 807ms/step - loss: 1.0015 - accuracy: 0.6016 - val_loss: 1.0305 - val_accuracy: 0.5808\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=3,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56ba2f61-41af-4092-8b03-5978559eb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('model_best_05_20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0a4e1e7-b6c7-4e47-b64d-414e3fb8750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_name = 'model_best_05_20.h5'\n",
    "client = storage.Client()\n",
    "\n",
    "blob = bucket.blob(blob_name)\n",
    "blob.upload_from_filename(blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8d1748c-ece8-4800-ac21-857f0b92d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Embedding(input_dim=num_words,output_dim=256,input_length=max_log_length))\n",
    "\n",
    "num_filters = 128\n",
    "\n",
    "model3.add(Conv1D(num_filters, 5, activation='relu'))\n",
    "model3.add(MaxPooling1D(pool_size=5))\n",
    "\n",
    "# model3.add(LSTM(units=128,recurrent_dropout=0.5))\n",
    "# model3.add(Dropout(0.5))\n",
    "\n",
    "model3.add(Conv1D(num_filters, 5, activation='relu'))\n",
    "model3.add(MaxPooling1D(pool_size=5))\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "# Add Dense layers\n",
    "hidden_units = [128, 64]\n",
    "for units in hidden_units:\n",
    "    model3.add(Dense(units, activation='relu'))\n",
    "    model3.add(Dropout(0.5))\n",
    "    \n",
    "model3.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c9118a7-4de2-4ae5-ae79-1bb0866f05d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2438/2438 [==============================] - 1242s 509ms/step - loss: 1.1571 - accuracy: 0.5260 - val_loss: 1.0405 - val_accuracy: 0.5794\n",
      "Epoch 2/3\n",
      "2438/2438 [==============================] - 1172s 481ms/step - loss: 0.9481 - accuracy: 0.6221 - val_loss: 1.0542 - val_accuracy: 0.5761\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=3,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5695c18b-ca66-45d7-8ed9-d5c735c472df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('model_best_05_20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78419050-07e5-47ba-ba34-6a85323a0825",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_name = 'model_best_05_20.h5'\n",
    "client = storage.Client()\n",
    "\n",
    "blob = bucket.blob(blob_name)\n",
    "blob.upload_from_filename(blob_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2ccef-7d27-4f40-a83d-bb39b0692049",
   "metadata": {},
   "source": [
    "Using convolutional layers in a neural network for text data can be beneficial for several reasons:\n",
    "\n",
    "Local Pattern Extraction: Convolutional layers can effectively capture local patterns and features in the text data. By applying filters of different sizes, the convolutional operation can detect patterns at various levels of granularity. This allows the model to learn relevant features such as n-grams, word combinations, or other local patterns that are indicative of the text's meaning or sentiment.\n",
    "\n",
    "Translation Invariance: Convolutional layers exhibit translation invariance, which means they can recognize patterns regardless of their exact position in the input. In the context of text data, this property is useful because the position of a particular word or phrase in a sentence may not always be critical for understanding its meaning. By capturing patterns irrespective of their location, convolutional layers can provide robust representations that are not overly sensitive to word order.\n",
    "\n",
    "Reduced Parameter Count: Convolutional layers can help reduce the number of parameters in the model compared to fully connected layers. This reduction is achieved by weight sharing through the use of filters. By sharing weights, the model can capture the same pattern or feature across different positions in the input, resulting in fewer trainable parameters. This parameter efficiency can make the model easier to train and less prone to overfitting, especially when dealing with limited amounts of text data.\n",
    "\n",
    "Hierarchical Feature Learning: Deep architectures with multiple convolutional layers can learn hierarchical representations of the input text. Lower-level convolutional layers can capture basic local features, while higher-level convolutional layers can learn more complex combinations of these features. This hierarchical learning enables the model to capture both low-level and high-level semantic information from the text.\n",
    "\n",
    "It's worth noting that while convolutional neural networks (CNNs) have primarily been associated with image processing tasks, they have been successfully adapted for natural language processing (NLP) tasks, including text classification. The convolutional operations in text CNNs are typically performed along the time dimension (i.e., word or character sequences) rather than across spatial dimensions (as in image CNNs).\n",
    "\n",
    "That being said, the effectiveness of using convolutional layers in text classification tasks may vary depending on the specific dataset and problem. It's recommended to experiment with different architectures and compare the performance with other approaches, such as recurrent neural networks (RNNs) or transformers, to determine the best choice for your particular task.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Regenerate response"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
