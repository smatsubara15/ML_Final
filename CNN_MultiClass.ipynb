{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f79843-0e13-43c4-a4cf-ba7de7e7ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, re, time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a474fcbe-fa4b-4101-99f7-8d9c63ff3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "import io\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket('nlp_final_data')\n",
    "\n",
    "blob = bucket.blob('songs_nGrams.csv')\n",
    "content = blob.download_as_string()\n",
    "\n",
    "df = pd.read_csv(io.BytesIO(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b0dd5fc-531b-49e0-a6ca-6bc8d6664547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['1-grams'] = df['1-grams'].apply(lambda x: x.strip('[]').replace('\\'', '').split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a38041-287a-4d9e-ac21-b45aa7005c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['songs'] = df['1-grams'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2db685f-9baa-497f-a403-0bbefe822811",
   "metadata": {},
   "outputs": [],
   "source": [
    "textVar = df['songs']\n",
    "targetVar = df['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a50f8fed-d5d6-454a-b5f3-0e6110481d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make our experiments repeatable\n",
    "np.random.seed(0)\n",
    "\n",
    "# Model Hyperparameters\n",
    "embedding_dim = 100\n",
    "\n",
    "# Training parameters. Here we specify the training of the net will use 64 examples for each backprop iteration\n",
    "batch_size = 128\n",
    "# We will go thru the entire data set 20 times\n",
    "num_epochs = 20\n",
    "\n",
    "# Prepossessing parameters\n",
    "# We will only input the first \"sequence_length\" words of every Yelp review (and pad out with nulls if the text is < \"sequence_length\n",
    "# We will also build our model using the most frequent 20000 words in our tweet 'dictionary'\n",
    "sequence_length = 200\n",
    "max_features = 2000\n",
    "\n",
    "#Specify the number of classes to predict (1 for binary classification or count unique values for multilabel classification)\n",
    "# num_classes = 1\n",
    "num_classes = targetVar.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb1540e-3aa3-4fca-b69c-5814eda45f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = textVar.values\n",
    "Y = pd.get_dummies(targetVar).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93e5e3fa-9cb9-4d5c-83fa-093621f30e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, val_samples, train_labels, val_labels = train_test_split(X,Y, stratify=targetVar, test_size = 0.33, random_state = 1010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4cb5904-0ecf-4533-8431-7d0d381cd30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 19:50:58.850525: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-19 19:50:58.850574: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-05-19 19:50:58.850611: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nlpfinal): /proc/driver/nvidia/version does not exist\n",
      "2023-05-19 19:50:58.852161: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TextVectorization(max_tokens=max_features, output_sequence_length=sequence_length, ngrams=None, pad_to_max_tokens=True)\n",
    "\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f9981a0-dbef-4d0f-81cf-cbbb224ff33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
    "X_test = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
    "\n",
    "Y_train = np.array(train_labels)\n",
    "Y_test = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "707e193a-290e-476c-8a74-96e16c45a20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41545 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "glove_dir = 'Data/'\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'), encoding=\"utf8\")\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cd02620-4e28-41da-9096-66eddd0e8564",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1832094e-3aa5-458e-9c95-28c14f28d25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 1950 words (50 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b94f852-9dec-4485-ac50-6ea76a80110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "940d315b-08bb-4527-a2ff-f4dcf3a8a8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 100)         200200    \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, None, 128)         64128     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, None, 128)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, None, 128)         82048     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, None, 128)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, None, 128)         82048     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 445,581\n",
      "Trainable params: 245,381\n",
      "Non-trainable params: 200,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense((num_classes), activation=\"softmax\")(x)\n",
    "model = keras.Model(int_sequences_input, preds)\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b4ea98-8128-4a2c-b3d9-eee59e29d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d8d8dca-9eab-431d-be43-6972d2472f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'create'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_2518/2734419677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#! pip install graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'create'"
     ]
    }
   ],
   "source": [
    "#! pip install graphviz\n",
    "SVG(model_to_dot(model, show_shapes=True, dpi=65).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebd90e50-7831-424d-be2c-674f306bbd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2268/2268 - 98s - loss: 1.1859 - acc: 0.5146 - val_loss: 1.1368 - val_acc: 0.5361 - 98s/epoch - 43ms/step\n",
      "Epoch 2/10\n",
      "2268/2268 - 95s - loss: 1.1193 - acc: 0.5448 - val_loss: 1.1322 - val_acc: 0.5381 - 95s/epoch - 42ms/step\n",
      "Epoch 3/10\n",
      "2268/2268 - 95s - loss: 1.0944 - acc: 0.5554 - val_loss: 1.0993 - val_acc: 0.5493 - 95s/epoch - 42ms/step\n",
      "Epoch 4/10\n",
      "2268/2268 - 95s - loss: 1.0782 - acc: 0.5633 - val_loss: 1.1089 - val_acc: 0.5509 - 95s/epoch - 42ms/step\n",
      "Epoch 5/10\n",
      "2268/2268 - 94s - loss: 1.0668 - acc: 0.5671 - val_loss: 1.0983 - val_acc: 0.5564 - 94s/epoch - 42ms/step\n",
      "Epoch 6/10\n",
      "2268/2268 - 95s - loss: 1.0582 - acc: 0.5711 - val_loss: 1.1045 - val_acc: 0.5554 - 95s/epoch - 42ms/step\n",
      "Epoch 7/10\n",
      "2268/2268 - 95s - loss: 1.0499 - acc: 0.5735 - val_loss: 1.1243 - val_acc: 0.5464 - 95s/epoch - 42ms/step\n",
      "Epoch 8/10\n",
      "2268/2268 - 94s - loss: 1.0443 - acc: 0.5761 - val_loss: 1.2799 - val_acc: 0.5063 - 94s/epoch - 42ms/step\n",
      "Epoch 9/10\n",
      "2268/2268 - 97s - loss: 1.0374 - acc: 0.5795 - val_loss: 1.1284 - val_acc: 0.5517 - 97s/epoch - 43ms/step\n",
      "Epoch 10/10\n",
      "2268/2268 - 95s - loss: 1.0336 - acc: 0.5820 - val_loss: 1.1829 - val_acc: 0.5385 - 95s/epoch - 42ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, \n",
    "                    epochs=10,\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5311831-4414-4f58-be9a-c0a6bfe33559",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_CNN_Test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a07c788-7886-4975-9069-52bdb14e1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client()\n",
    "\n",
    "blob = bucket.blob('model_CNN_Test.h5')\n",
    "blob.upload_from_filename('model_CNN_Test.h5')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
